{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sandbox.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ZIZozNO0Gctj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from quiz import get_weights, get_biases, linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EiItEDAmHPVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mnist_features_labels(n_labels):\n",
        "    \"\"\"\n",
        "    Gets the first <n> labels from the MNIST dataset\n",
        "    :param n_labels: Number of labels to use\n",
        "    :return: Tuple of feature list and label list\n",
        "    \"\"\"\n",
        "    mnist_features = []\n",
        "    mnist_labels = []\n",
        "\n",
        "    mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
        "\n",
        "    # In order to make quizzes run faster, we're only looking at 10000 images\n",
        "    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n",
        "\n",
        "        # Add features and labels if it's for the first <n>th labels\n",
        "        if mnist_label[:n_labels].any():\n",
        "            mnist_features.append(mnist_feature)\n",
        "            mnist_labels.append(mnist_label[:n_labels])\n",
        "\n",
        "    return mnist_features, mnist_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MboU_OJHYD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of features (28*28 image is 784 features)\n",
        "n_features = 784\n",
        "# Number of labels\n",
        "n_labels = 3\n",
        "\n",
        "# Features and Labels\n",
        "features = tf.placeholder(tf.float32)\n",
        "labels = tf.placeholder(tf.float32)\n",
        "\n",
        "# Weights and Biases\n",
        "w = get_weights(n_features, n_labels)\n",
        "b = get_biases(n_labels)\n",
        "\n",
        "# Linear Function xW + b\n",
        "logits = linear(features, w, b)\n",
        "\n",
        "# Training data\n",
        "train_features, train_labels = mnist_features_labels(n_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XkwDWZwaHcTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    # TODO: Initialize session variables\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    \n",
        "    # Softmax\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "\n",
        "    # Cross entropy\n",
        "    # This quantifies how far off the predictions were.\n",
        "    # You'll learn more about this in future lessons.\n",
        "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
        "\n",
        "    # Training loss\n",
        "    # You'll learn more about this in future lessons.\n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "    # Rate at which the weights are changed\n",
        "    # You'll learn more about this in future lessons.\n",
        "    learning_rate = 0.08\n",
        "\n",
        "    # Gradient Descent\n",
        "    # This is the method used to train the model\n",
        "    # You'll learn more about this in future lessons.\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "    # Run optimizer and get loss\n",
        "    _, l = session.run(\n",
        "        [optimizer, loss],\n",
        "        feed_dict={features: train_features, labels: train_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-SKzYYYHkX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0afae019-edc5-48a2-bccc-f82fb674177c"
      },
      "cell_type": "code",
      "source": [
        "# Print loss\n",
        "print('Loss: {}'.format(l))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 9.585176467895508\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}